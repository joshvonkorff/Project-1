{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "\n",
    "# Read DataFrame df from csv file\n",
    "# Note: some of these elements will be NaN because the csv file has some missing values,\n",
    "# i.e. two adjacent commas with nothing between them.\n",
    "df = pd.read_csv(\"F00005811-WV6_Data_ascii_delimited_v_2016_01_01/WV6_Data_ascii_delimited_v_2016_01_01.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification (.sts) file with description string for each survey item\n",
    "specfile = \"F00005811-WV6_Data_ascii_delimited_v_2016_01_01/WV6_Data_ascii_delimited_v_2016_01_01.sts\"\n",
    "\n",
    "def represents_int(s):\n",
    "    '''\n",
    "    represents_int determines whether its argument is a string that\n",
    "    represents and integer.\n",
    "    '''\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def read_spec(filename):\n",
    "    '''\n",
    "    read_spec reads the World Value Survey .sts specification file for \"Wave 6.\"\n",
    "    It returns a series where the index is a code for each column and \n",
    "    the value is a descriptive string.\n",
    "    This file contains code descriptions for the 430 codes in Wave 6.\n",
    "    '''\n",
    "    s = pd.Series([])\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            # An example line from the spec file is:\n",
    "            #    V4 5 (F2) [<= -1] {Important in life: Family} \\V4\n",
    "            # All we care about from this line is arr[0], which is \"V4\", \n",
    "            # and what's in brackets {}\n",
    "            arr = line.split()\n",
    "            if len(arr) < 2 or not represents_int(arr[1]):\n",
    "                continue\n",
    "            # The \"code\" is a string of letters and numbers, like \"V4\" or \"MN_228R\" \n",
    "            code = arr[0]\n",
    "            # Need to parse the code description in between the { and }\n",
    "            # There may be spaces inside the description, so the description may span\n",
    "            # several elements\n",
    "            desclist = [i for i, x in enumerate(arr) if \"{\" in x or \"}\" in x]\n",
    "            # Some lines might not be a description of a code; they won't have brackets { }\n",
    "            if not desclist:\n",
    "                continue\n",
    "            desc = \"\"\n",
    "            min = desclist[0]\n",
    "            max = desclist[-1]\n",
    "            for i in range(min, max + 1):\n",
    "                desc += arr[i]\n",
    "                if i < max:\n",
    "                    desc += \" \"\n",
    "            # Append the code: desc pairs one by one\n",
    "            sapp = pd.Series({code: desc})\n",
    "            s = s.append(sapp)\n",
    "    return s\n",
    "\n",
    "spec_series = read_spec(specfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column names to the codes from the .sts specifications file\n",
    "df.columns = spec_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subcluster(X):\n",
    "    '''\n",
    "    This function is used to take a single cluster and break it into one or two subclusters.\n",
    "    This is useful because our clusters will contain both correlated and anticorrelated\n",
    "    components.  We want to distinguish between these sets of components.\n",
    "    Note, however, that we cannot interpret this result without resorting to a manual\n",
    "    check of the .sts specifications file to see whether that survey item\n",
    "    had low numbers = most positive opinion or high numbers = most positive opinion\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(X)\n",
    "    p = kmeans.predict(X)\n",
    "    c = np.corrcoef([row for row in X])\n",
    "    # Add the R-squared values for every cross-cluster pair\n",
    "    # with a minus sign when R is negative.  If the result is negative, it means\n",
    "    # the clusters are anticorrelated and there should be two clusters.  \n",
    "    # Otherwise, there should be one.\n",
    "    csum = sum(np.sign(c[i,j])*c[i, j]**2 \n",
    "                for i, v in enumerate(p) \n",
    "                for j, w in enumerate(p) if v != w)   \n",
    "    #The following code can be used to check the number of subclusters in each cluster\n",
    "    #string = \"Mini-cluster sum: \" + str(csum)\n",
    "    #if csum > 0:\n",
    "    #    string += \"(1 cluster)\"\n",
    "    #else:\n",
    "    #    string += \"(2 clusters)\"\n",
    "    #print(string)\n",
    "    if csum < 0:\n",
    "        return p # There should be two clusters\n",
    "    else:\n",
    "        return np.zeros(len(X)) # There should be only one cluster\n",
    "\n",
    "def find_bad_nums(df, numrows, threshold, min, max):\n",
    "    '''\n",
    "    Given a DataFrame, find the numbers of the columns where more than\n",
    "    10% of the rows are -4.  This means they were not included in the\n",
    "    survey for 10% or more of the respondents.  I don't want to attempt to fill\n",
    "    in the -4's with mean values if there are too many -4's.\n",
    "    '''\n",
    "    badlst = []\n",
    "    for n in range(min, max):\n",
    "        try:\n",
    "            frac = df[df.columns[n]].value_counts()[-4] / numrows\n",
    "            if frac > 0.1:\n",
    "                badlst.append(n)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return badlst\n",
    "\n",
    "def custom_dist(row1, row2):\n",
    "    '''\n",
    "    The custom distance is the minimum of the usual distance\n",
    "    along with the distance between one and the negative of the other.\n",
    "    '''\n",
    "    return min(\n",
    "        np.sqrt(np.sum((row1 - row2)**2)),\n",
    "        np.sqrt(np.sum((row1 + row2)**2))\n",
    "    )\n",
    "\n",
    "def get_all_nums(bad_nums):\n",
    "  # These are the numbers for Inglehart's traditional vs. secular-rational items\n",
    "  # I had to look these up manually from Inglehart's book\n",
    "  trad_nums = [173, 344, 236, 392, 391, 10, 51, 170, 26, \n",
    "               112, 168, 240, 9, 239, 88, 99, 237, 49, 5, 150]\n",
    "  trad_nums = np.array(trad_nums)-1 # column number equals printed number minus one\n",
    "  trad_nums = [a for a in trad_nums if a not in bad_nums]\n",
    "\n",
    "  # These are the numbers of Inglehart's survival vs. self-expression items        \n",
    "  # I had to look these up manually from Inglehart's book\n",
    "  surv_nums = [343, 11, 234, 89, 25, 53, 62, 56, 41, 39, 40, 101, \n",
    "               12, 47, 102, 57, 54, 43, 14, 16, 17, 7, 6, 148, 90, 161]\n",
    "  surv_nums = np.array(surv_nums)-1\n",
    "  surv_nums = [a for a in surv_nums if a not in bad_nums]\n",
    "\n",
    "  # Group the two lists together.  Let's see if clustering can separate them again\n",
    "  all_nums = trad_nums + surv_nums\n",
    "  return all_nums\n",
    "\n",
    "def get_zscore_matrix(df, numrows, all_nums):\n",
    "  '''\n",
    "  Given a DataFrame, a number of rows, and a list of column numbers (all_nums)\n",
    "  Generate a zscore matrix, which is transposed relative to the DataFrame.\n",
    "  The zscore matrix has rows that add to zero, their variance is 1, and each\n",
    "  row in the zscore matrix corresponds to a column of the DataFrame.\n",
    "  '''\n",
    "  # Turn the df columns into rows (transpose) and select those rowse corresponding to all_nums\n",
    "  X = df2.iloc[0:numrows].T.iloc[all_nums].as_matrix() # matrix of questions from start to end\n",
    "  # insert nan wherever X < 0.  Note, this will trigger a runtime warning\n",
    "  # saying that X < 0 results in some nan value where X is already nan. \n",
    "  # That's fine, those values are already nan and will remain nan.\n",
    "  X[X < 0] = np.nan \n",
    "  # compute the mean of each survey item, averaging over all respondents\n",
    "  row_means = np.nanmean(X, axis=1)\n",
    "  # find the indices of the nans so that we can replace them by the mean value\n",
    "  inds = np.where(np.isnan(X))\n",
    "  # insert the row means in place of the nans\n",
    "  X[inds] = np.take(row_means, inds[0])\n",
    "  # Replace the respondents' answers by their z-scores for each survey item.\n",
    "  # This is necessary so that we can perform a cluster analysis, since different\n",
    "  # survey items are on wildly different scales.\n",
    "  X = scipy.stats.zscore(X, axis=1)\n",
    "  return X\n",
    "\n",
    "def get_subc_list(X, labels):\n",
    "  '''\n",
    "  Get a list of subclusters for each cluster.\n",
    "  Each item within a cluster is coded as either 0 or 1 using the subcluster function\n",
    "  defined in this file.  Please see the subcluster function for further details.\n",
    "  '''\n",
    "  # indlist = [[row indices of X where cluster label = 0], [indices where label = 1], ...]\n",
    "  indlist = [np.where(labels == a) for a in sorted(np.unique(labels))]\n",
    "  # subXlist = [X rows where label = 0, X rows where label = 1, ... ]\n",
    "  subXlist = [X[inds[0]] for inds in indlist] # inds will be a 1-elt. tuple, so take inds[0]\n",
    "  # inv = [[predictions for label = 0], [predictions for label = 1], ...]\n",
    "  # each prediction will be either 0 or 1 depending on how this item is inverted relative to\n",
    "  # the other items in the cluster.  All the 0's are correlated with each other and\n",
    "  # anticorrelated with the 1's.\n",
    "  subc_list = [subcluster(subX) for subX in subXlist]\n",
    "  return subc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to analyze:\n",
      "(a) the world, two clusters\n",
      "(b) the world, four clusters\n",
      "(c) United States, two clusters\n",
      "(d) United States, four clusters\n",
      ">d\n",
      "The number of good survey items for the United States is:  31\n",
      "The number of respondents for the United States is:  2232\n",
      "How to interpret these resuls:\n",
      "\n",
      "Clustering was performed by Affinity Propagation.\n",
      "The number 0, 1, 2, or 3 is the cluster number.  All 0's are in the same cluster.\n",
      "Surv-Exp means that this item is classified as Survival vs. Self-Expression by Inglehart.\n",
      "Trad-Sec means that this item is classified as Traditional vs. Secular by Inglehart.\n",
      "The phrase in brackets { } describes the nature of the item.\n",
      "\n",
      "A's are correlated with other A's and anticorrelated with B's in that cluster.\n",
      "However, to interpret this you need to know whether the scale on that item runs from e.g.\n",
      "1 (highest) to 5 (lowest) or the reverse.  This requires manually consulting a table.\n",
      "\n",
      "\n",
      "A (0, 'Trad-Sec', '{Important in life: Family}')\n",
      "A (0, 'Trad-Sec', '{Important in life: Work}')\n",
      "A (0, 'Trad-Sec', '{Important in life: Religion}')\n",
      "B (0, 'Surv-Exp', '{Important child qualities: Imagination}')\n",
      "B (0, 'Trad-Sec', '{Active/Inactive membership: Church or religious organization}')\n",
      "A (0, 'Trad-Sec', '{One of my main goals in life has been to make my parents proud}')\n",
      "A (0, 'Surv-Exp', '{Being a housewife is just as fulfilling as working for pay}')\n",
      "A (0, 'Trad-Sec', '{Confidence: The Churches}')\n",
      "A (0, 'Trad-Sec', '{Justifiable: Divorce}')\n",
      "A (0, 'Trad-Sec', '{Justifiable: Suicide}')\n",
      "A (0, 'Trad-Sec', '{Autonomy Index}')\n",
      "A (0, 'Trad-Sec', '{Overall Secular Values-1: Inverse respect for authority}')\n",
      "A (0, 'Trad-Sec', '{Overall Secular Values-1: Inverse national pride}')\n",
      "A (1, 'Surv-Exp', '{Important in life: Friends}')\n",
      "A (1, 'Surv-Exp', '{Important in life: Leisure time}')\n",
      "A (1, 'Surv-Exp', '{Feeling of happiness}')\n",
      "A (1, 'Surv-Exp', '{State of health (subjective)}')\n",
      "B (1, 'Surv-Exp', '{How much freedom of choice and control over own life}')\n",
      "B (1, 'Surv-Exp', '{Satisfaction with financial situation of household}')\n",
      "B (2, 'Surv-Exp', '{Important child qualities: Hard work}')\n",
      "A (2, 'Surv-Exp', '{Important child qualities: Tolerance and respect for other people}')\n",
      "B (2, 'Surv-Exp', '{When jobs are scarce, men should have more right to a job than women}')\n",
      "B (2, 'Trad-Sec', \"{If a woman earns more money than her husband, it's almost certain to cause problems}\")\n",
      "B (2, 'Surv-Exp', '{On the whole, men make better political leaders than women do}')\n",
      "B (2, 'Surv-Exp', '{A university education is more important for a boy than for a girl}')\n",
      "A (2, 'Surv-Exp', '{Government responsibility}')\n",
      "A (3, 'Surv-Exp', '{Most people can be trusted}')\n",
      "A (3, 'Trad-Sec', '{Interest in politics}')\n",
      "A (3, 'Surv-Exp', '{Private vs state ownership of business}')\n",
      "B (3, 'Surv-Exp', '{Importance of democracy}')\n",
      "B (3, 'Surv-Exp', '{Post-materialist index (4-item)}')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:91: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "  print(\"Would you like to analyze:\")\n",
    "  print(\"(a) the world, two clusters\")\n",
    "  print(\"(b) the world, four clusters\")\n",
    "  print(\"(c) United States, two clusters\")\n",
    "  print(\"(d) United States, four clusters\")\n",
    "  letter = input(\">\")\n",
    "  if letter in list(\"abcd\"):\n",
    "    break\n",
    "  else:\n",
    "    print(\"Input error: please enter a letter a-d\")\n",
    "\n",
    "dpref = {\"a\": -700, \"b\": -500, \"c\": -110, \"d\": -75}\n",
    "dcode = {\"c\": 840, \"d\": 840}\n",
    "dname = {\"a\": \"the world\", \"b\": \"the world\", \"c\": \"the United States\", \"d\": \"the United States\"}\n",
    "numcols = len(df.columns)\n",
    "\n",
    "if letter == \"a\" or letter == \"b\":\n",
    "  df2 = df.copy() # the world\n",
    "else:\n",
    "  df2 = df[df['V2'] == dcode[letter]].copy() # U.S. only\n",
    "numrows = len(df2.index)\n",
    "\n",
    "# These are the numbers for \"bad\" survey items (columns) where more than 10% of the data is NaN.\n",
    "# Many of these have much more than 10% being NaN.\n",
    "# min survey item = 4 because the first four items in the list are not really survey items\n",
    "bad_nums = find_bad_nums(df, numrows, threshold = 0.1, min = 4, max=numcols)\n",
    "\n",
    "all_nums = get_all_nums(bad_nums)\n",
    "\n",
    "all_nums.sort()\n",
    "\n",
    "print(\"The number of good survey items for\", dname[letter], \"is: \", len(all_nums))\n",
    "print(\"The number of respondents for\", dname[letter], \"is: \", numrows)\n",
    "\n",
    "# The preference value for Affinity Propagation has to be set via trial and error.\n",
    "# The smaller it is, the fewer clusters will appear.\n",
    "# If it is too small, there will be only one cluster.\n",
    "clust = sklearn.cluster.AffinityPropagation(affinity=\"precomputed\", preference = dpref[letter])\n",
    "\n",
    "X = get_zscore_matrix(df2, numrows, all_nums)\n",
    "\n",
    "# Compute affinity matrix.  The affinity should be small when two items are far apart.\n",
    "# That means we need to take the negative of the distance between the items.\n",
    "# Also, we want to note correlations _and_ anticorrelations.  That means we should\n",
    "# compute both the distance between row1 and row2 _and_ the distance between\n",
    "# row1 and -row2.  We then take the minimum of these as the user-defined distance.\n",
    "# In other words, [1, 0, -1, 0] should be \"the same as\" [-1, 0, 1, 0].\n",
    "Xaff = -np.array(\n",
    "                  [[custom_dist(row1, row2) for row1 in X] \n",
    "                  for row2 in X]\n",
    "                )\n",
    "\n",
    "clust.fit(Xaff)\n",
    "labels = clust.labels_\n",
    "\n",
    "# Now we have to determine if each survey item in each cluster was correlated or anticorrelated\n",
    "# with the other survey items\n",
    "subc_list = get_subc_list(X, labels)\n",
    "\n",
    "print(\"How to interpret these resuls:\")\n",
    "print(\"\")\n",
    "print(\"Clustering was performed by Affinity Propagation.\")\n",
    "print(\"The number 0, 1, 2, or 3 is the cluster number.  All 0's are in the same cluster.\")\n",
    "print(\"Surv-Exp means that this item is classified as Survival vs. Self-Expression by Inglehart.\")\n",
    "print(\"Trad-Sec means that this item is classified as Traditional vs. Secular by Inglehart.\")\n",
    "print(\"The phrase in brackets { } describes the nature of the item.\")\n",
    "print(\"\")\n",
    "print(\"A's are correlated with other A's and anticorrelated with B's in that cluster.\")\n",
    "print(\"However, to interpret this you need to know whether the scale on that item runs from e.g.\")\n",
    "print(\"1 (highest) to 5 (lowest) or the reverse.  This requires manually consulting a table.\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "predlist = [(a[1],\n",
    "             \"Trad-Sec\" if all_nums[a[0]] in trad_nums else \"Surv-Exp\",\n",
    "             spec_series.iloc[all_nums[a[0]]],\n",
    "             all_nums[a[0]]\n",
    "            ) for a in enumerate(labels)]\n",
    "# Sort by cluster, then by survey item number\n",
    "predlist.sort(key = lambda x: (x[0], x[3]))\n",
    "joinedlist  = []\n",
    "for i in subc_list:\n",
    "    joinedlist = joinedlist + list(i)\n",
    "# joinedlist is sorted in the same way as predlist, so they can be zipped\n",
    "for x, i in zip(predlist, joinedlist):\n",
    "    print(\"A\" if i==1 else \"B\", x[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-cluster sum:  -0.45267483007839393\n",
      "[0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "X2 = X[np.where(labels == 3)]\n",
    "print(subcluster(X2))\n",
    "#c = np.corrcoef([row for row in X2])\n",
    "#print(c)\n",
    "#X2 = X[np.where(labels == 3)]\n",
    "#kmeans = KMeans(n_clusters=2)\n",
    "#kmeans.fit(X2)\n",
    "#p = kmeans.predict(X2)\n",
    "#print(p)\n",
    "#cc = ((X2[0] + X2[1])/2, (X2[2] + X2[3] + X2[4])/3)\n",
    "#print(sum(np.sum((cc[0]-X2[n])**2) for n in np.arange(0, 3))\n",
    "# + sum(np.sum((cc[1]-X2[n])**2) for n in np.arange(3, 5)))\n",
    "#print(sum(np.sum((cc[0]-X2[n])**2) for n in np.arange(0, 2))\n",
    "# + sum(np.sum((cc[1]-X2[n])**2) for n in np.arange(2, 5)))\n",
    "# correlation is the sum of x * y\n",
    "# distance is the sum of (x - y)**2 = x**2 + y**2 - 2 * x * y = 2 N - 2 * x * y\n",
    "# So the distance is -abs() of the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Interview number}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90349"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(s.loc['V3'])\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for n_clusters =  2  is  -6663449.859536235\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from sklearn.cluster import KMeans\n",
    "start = 4\n",
    "end = 43\n",
    "for n in range(2, 3):\n",
    "  kmeans = KMeans(n_clusters=n)\n",
    "  X = df.iloc[0:90348].T.iloc[start:end+1].as_matrix() # matrix of questions from start to end\n",
    "  # The next four lines will insert nan wherever X < 0, then compute the mean of each row,\n",
    "  # then insert that mean wherever there is a nan\n",
    "  X[X < 0] = np.nan # insert nan wherever X < 0\n",
    "  row_means = np.nanmean(X, axis=1) # compute the mean of each row\n",
    "  inds = np.where(np.isnan(X)) # find the indices of the nans\n",
    "  X[inds] = np.take(row_means, inds[0]) # insert the row means\n",
    "  # print(X[20][0:10])\n",
    "  # print(X[0, 508], \" should be 1.1041382\") # check that the first mean is inserted\n",
    "  # print(X[39, 66492], \" should be 1.71830793\") # check that the last mean is inserted\n",
    "  X = scipy.stats.zscore(X, axis=1)\n",
    "  X = np.vstack((X, -X))\n",
    "\n",
    "  kmeans.fit(X)\n",
    "  p = kmeans.predict(X)\n",
    "  sc = kmeans.score(X)\n",
    "  print(\"The score for n_clusters = \", n, \" is \", sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "n_clusters = 8\n",
    "start = 4\n",
    "end = 43\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "X = df.iloc[0:90348].T.iloc[start:end+1].as_matrix() # matrix of questions from start to end\n",
    "\n",
    "# The next four lines will insert nan wherever X < 0, then compute the mean of each row,\n",
    "# then insert that mean wherever there is a nan\n",
    "X[X < 0] = np.nan # insert nan wherever X < 0\n",
    "row_means = np.nanmean(X, axis=1) # compute the mean of each row\n",
    "inds = np.where(np.isnan(X)) # find the indices of the nans\n",
    "X[inds] = np.take(row_means, inds[0]) # insert the row means\n",
    "# print(X[0, 508], \" should be 1.1041382\") # check that the first mean is inserted\n",
    "# print(X[39, 66492], \" should be 1.71830793\") # check that the last mean is inserted\n",
    "   \n",
    "X = scipy.stats.zscore(X, axis=1)\n",
    "X = np.vstack((X, -X))\n",
    "#print(len(X[0]), \" should be thousands\") # This checks that X[0] is an individual question with 90k respondents\n",
    "#print(sum(X[25]), \" should be zero\") # This checks that X[0] sums to zero (Z scores)\n",
    "\n",
    "kmeans.fit(X)\n",
    "p = kmeans.predict(X)\n",
    "predlist = [(a[1], s[a[0]+start] if a[0] <= end-start \\\n",
    "             else \"INV \" + s[a[0]-end-1+2*start]) for a in enumerate(p)]\n",
    "predlist.sort(key = lambda x: x[0])\n",
    "for x in predlist:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to analyze:\n",
      "(a) the world, two clusters\n",
      "(b) the world, four clusters\n",
      "(c) United States, two clusters\n",
      "(d) United States, four clusters\n",
      ">c\n",
      "The number of respondents for the United States is:  2232\n",
      "How to interpret these resuls:\n",
      "\n",
      "Clustering was performed by Affinity Propagation.\n",
      "The number 0, 1, 2, or 3 is the cluster number.  All 0's are in the same cluster.\n",
      "Surv-Exp means that this item is classified as Survival vs. Self-Expression by Inglehart.\n",
      "Trad-Sec means that this item is classified as Traditional vs. Secular by Inglehart.\n",
      "The phrase in brackets { } describes the nature of the item.\n",
      "\n",
      "A's are correlated with other A's and anticorrelated with B's in that cluster.\n",
      "However, to interpret this you need to know whether the scale on that item runs from\n",
      "1 (highest) to 5 (lowest) or the reverse.  This requires manually consulting a table.\n",
      "\n",
      "\n",
      "B (0, 'Trad-Sec', '{Important in life: Family}')\n",
      "B (0, 'Surv-Exp', '{Important in life: Friends}')\n",
      "B (0, 'Trad-Sec', '{Important in life: Work}')\n",
      "B (0, 'Trad-Sec', '{Important in life: Religion}')\n",
      "B (0, 'Surv-Exp', '{Feeling of happiness}')\n",
      "A (0, 'Trad-Sec', '{Active/Inactive membership: Church or religious organization}')\n",
      "B (0, 'Surv-Exp', '{Would not like to have as neighbors: Heavy drinkers}')\n",
      "B (0, 'Trad-Sec', '{One of my main goals in life has been to make my parents proud}')\n",
      "B (0, 'Surv-Exp', '{Being a housewife is just as fulfilling as working for pay}')\n",
      "A (0, 'Surv-Exp', '{How much freedom of choice and control over own life}')\n",
      "A (0, 'Surv-Exp', '{Satisfaction with financial situation of household}')\n",
      "B (0, 'Trad-Sec', '{Interest in politics}')\n",
      "B (0, 'Trad-Sec', '{Confidence: The Churches}')\n",
      "B (0, 'Trad-Sec', '{Religious person}')\n",
      "B (0, 'Trad-Sec', '{Believe in: hell}')\n",
      "A (0, 'Trad-Sec', '{How important is God in your life}')\n",
      "B (0, 'Trad-Sec', '{Autonomy Index}')\n",
      "B (0, 'Trad-Sec', '{Overall Secular Values-1: Inverse respect for authority}')\n",
      "B (0, 'Trad-Sec', '{Overall Secular Values-1: Inverse national pride}')\n",
      "A (1, 'Surv-Exp', '{Important in life: Leisure time}')\n",
      "A (1, 'Surv-Exp', '{State of health (subjective)}')\n",
      "B (1, 'Surv-Exp', '{Important child qualities: Hard work}')\n",
      "A (1, 'Surv-Exp', '{Important child qualities: Imagination}')\n",
      "A (1, 'Surv-Exp', '{Important child qualities: Tolerance and respect for other people}')\n",
      "A (1, 'Surv-Exp', '{Most people can be trusted}')\n",
      "B (1, 'Surv-Exp', '{Would not like to have as neighbors: People who have AIDS}')\n",
      "B (1, 'Surv-Exp', '{Would not like to have as neighbors: Immigrants/foreign workers}')\n",
      "B (1, 'Surv-Exp', '{Would not like to have as neighbors: Homosexuals}')\n",
      "B (1, 'Surv-Exp', '{When jobs are scarce, men should have more right to a job than women}')\n",
      "B (1, 'Trad-Sec', \"{If a woman earns more money than her husband, it's almost certain to cause problems}\")\n",
      "B (1, 'Surv-Exp', '{On the whole, men make better political leaders than women do}')\n",
      "B (1, 'Surv-Exp', '{A university education is more important for a boy than for a girl}')\n",
      "A (1, 'Surv-Exp', '{Political action: Signing a petition}')\n",
      "A (1, 'Surv-Exp', '{Political action: Joining in boycotts}')\n",
      "A (1, 'Trad-Sec', '{Self positioning in political scale}')\n",
      "A (1, 'Surv-Exp', '{Private vs state ownership of business}')\n",
      "A (1, 'Surv-Exp', '{Government responsibility}')\n",
      "B (1, 'Surv-Exp', '{Political system: Having a strong leader who does not have to bother with parliament and elections}')\n",
      "B (1, 'Trad-Sec', '{Political system: Having the army rule}')\n",
      "B (1, 'Surv-Exp', '{Importance of democracy}')\n",
      "B (1, 'Surv-Exp', '{Justifiable: Homosexuality}')\n",
      "B (1, 'Trad-Sec', '{Justifiable: Abortion}')\n",
      "B (1, 'Trad-Sec', '{Justifiable: Divorce}')\n",
      "B (1, 'Trad-Sec', '{Justifiable: Suicide}')\n",
      "B (1, 'Surv-Exp', '{Post-materialist index (4-item)}')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal is now to see how many of the df values are negative and how they are formatted.\n",
    "Conclusion: 25% of the question-respondent pairs are \"not asked in the survey,\" wihle only about 2% of other question-respondent pairs have negative values. \n",
    "Now, which questions are not asked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stotal = df[df.columns[4]].value_counts()\n",
    "for n in range(5, 430):\n",
    "    snext = df[df.columns[n]].value_counts()\n",
    "    stotal = stotal.add(snext, fill_value=0)\n",
    "print(stotal.loc[[-5, -4, -3, -2, -1]] / 90348 / 430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 58, 77, 92, 93, 94, 95, 96, 97, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 234, 237, 239, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 273, 274, 275, 276, 277, 278, 279, 280, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 312, 314, 315, 319, 323, 324, 325, 326, 327, 329, 330, 331, 336, 340, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385]\n",
      "45 0.987\n",
      "58 0.991\n",
      "77 0.528\n",
      "92 0.109\n",
      "93 0.126\n",
      "94 0.140\n",
      "95 0.140\n",
      "96 0.140\n",
      "97 0.167\n",
      "128 0.808\n",
      "129 0.921\n",
      "130 0.989\n",
      "131 0.973\n",
      "132 0.977\n",
      "133 0.953\n",
      "134 0.950\n",
      "135 0.877\n",
      "136 0.874\n",
      "137 0.937\n",
      "138 0.991\n",
      "139 0.987\n",
      "140 0.924\n",
      "141 0.983\n",
      "142 0.987\n",
      "143 0.899\n",
      "190 0.581\n",
      "191 0.581\n",
      "192 0.581\n",
      "193 0.581\n",
      "194 0.581\n",
      "195 0.581\n",
      "196 0.581\n",
      "197 0.581\n",
      "198 0.581\n",
      "199 0.581\n",
      "234 0.265\n",
      "237 0.120\n",
      "239 0.508\n",
      "247 0.819\n",
      "248 0.973\n",
      "249 0.987\n",
      "250 0.989\n",
      "251 0.973\n",
      "252 0.900\n",
      "253 0.953\n",
      "254 0.937\n",
      "255 0.978\n",
      "256 0.866\n",
      "257 0.874\n",
      "258 0.937\n",
      "259 0.920\n",
      "260 0.983\n",
      "261 0.976\n",
      "262 0.986\n",
      "263 0.983\n",
      "273 0.974\n",
      "274 0.974\n",
      "275 0.974\n",
      "276 0.974\n",
      "277 0.974\n",
      "278 0.974\n",
      "279 0.974\n",
      "280 0.974\n",
      "284 0.123\n",
      "285 0.977\n",
      "286 0.335\n",
      "287 0.335\n",
      "288 0.348\n",
      "289 0.335\n",
      "290 0.335\n",
      "291 0.335\n",
      "292 0.335\n",
      "293 0.335\n",
      "294 0.335\n",
      "295 0.346\n",
      "296 0.346\n",
      "312 0.984\n",
      "314 0.984\n",
      "315 0.119\n",
      "319 0.804\n",
      "323 0.123\n",
      "324 0.206\n",
      "325 0.883\n",
      "326 0.165\n",
      "327 0.118\n",
      "329 0.651\n",
      "330 0.894\n",
      "331 0.963\n",
      "336 0.493\n",
      "340 0.961\n",
      "344 0.908\n",
      "345 0.895\n",
      "346 0.895\n",
      "347 0.895\n",
      "348 0.895\n",
      "349 0.895\n",
      "350 0.895\n",
      "351 0.895\n",
      "352 0.895\n",
      "353 0.908\n",
      "354 0.908\n",
      "355 0.895\n",
      "356 0.895\n",
      "357 0.895\n",
      "358 0.895\n",
      "359 0.908\n",
      "360 0.895\n",
      "361 0.895\n",
      "362 0.895\n",
      "363 0.885\n",
      "364 0.908\n",
      "365 0.895\n",
      "366 0.895\n",
      "367 0.895\n",
      "368 0.908\n",
      "369 0.908\n",
      "370 0.908\n",
      "371 0.908\n",
      "372 0.908\n",
      "373 0.908\n",
      "374 0.908\n",
      "375 0.908\n",
      "376 0.908\n",
      "377 0.908\n",
      "378 0.908\n",
      "379 0.908\n",
      "380 0.908\n",
      "381 0.908\n",
      "382 0.908\n",
      "383 0.895\n",
      "384 0.895\n",
      "385 0.895\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "print(badlst)\n",
    "    \n",
    "for n in range(4, 430):\n",
    "    try:\n",
    "        frac = df[df.columns[n]].value_counts()[-4] / 90348\n",
    "        if frac > 0.1:\n",
    "            print(n, \"{:.3f}\".format(frac))\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the bad questions (with more than 10% as -4 \"not asked\") are 45, 58, 77, 92-97, 128-143, 190-199, 234, 237, 239, 247-263, 273-280, 284-296, 312, 314, 315, 319, 323-327, 329-331, 336, 340, 344-385."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1, 13).reshape(3, 4)\n",
    "arr[arr > 6] = 0\n",
    "print(np.average(arr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.55560814, -0.54335337],\n",
       "       [ 0.55560814,  1.        , -0.64727651],\n",
       "       [-0.54335337, -0.64727651,  1.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is testing whether the religion-related elements are correlated.\n",
    "# It turns out that 167 and 168 are inverted with smaller numbers being more religious\n",
    "X = df.iloc[0:90348].T.iloc[[167, 168, 172]].as_matrix()\n",
    "X[X < 0] = np.nan # insert nan wherever X < 0.  Note, this will trigger a runtime error\n",
    "# saying that X < 0 results in some nan value where X is nan.  That's fine, those values\n",
    "# are already nan and will remain nan.\n",
    "row_means = np.nanmean(X, axis=1) # compute the mean of each row\n",
    "inds = np.where(np.isnan(X)) # find the indices of the nans\n",
    "X[inds] = np.take(row_means, inds[0]) # insert the row means\n",
    "np.corrcoef([X[0], X[1], X[2]])\n",
    "#np.corrcoef([df['V147'], df['V148'], df['V152']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
